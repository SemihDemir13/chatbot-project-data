{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMORnB8Xh0eJTE5P4N16ILS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SemihDemir13/chatbot-project-data/blob/main/V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4OtuaCGUdFt-"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "print(\"Gerekli kÃ¼tÃ¼phaneler kuruluyor...\")\n",
        "!pip install -q -U transformers huggingface_hub accelerate sentence-transformers torch langchain langchain-community langchain-huggingface chromadb pandas\n",
        "print(\"Kurulum tamamlandÄ±.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Token'Ä±nÄ± girdikten sonra 'Login successful' yazÄ±sÄ±nÄ± gÃ¶rmelisin.\n",
        "login()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kpe-lcQXdR3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "print(\"Model yÃ¼kleniyor... (Biraz sabÄ±r)\")\n",
        "\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    # Colab GPU'su kullanÄ±lsÄ±n diye device_map=\"auto\" diyoruz\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Text generation pipeline'Ä± oluÅŸturuyoruz\n",
        "    llm_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=250 # CevabÄ±n uzunluÄŸu\n",
        "    )\n",
        "    print(\"âœ… Model baÅŸarÄ±yla yÃ¼klendi!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ HATA: Model yÃ¼klenemedi. LÃ¼tfen HÃœCRE 2'de token girdiÄŸinizden ve modelin lisansÄ±nÄ± kabul ettiÄŸinizden emin olun.\\nHata: {e}\")\n",
        ""
      ],
      "metadata": {
        "collapsed": true,
        "id": "pxrVTWwldi5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "print(\"CSV dosyasÄ± okunuyor ve veri formatlanÄ±yor...\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('netflix_titles.csv')\n",
        "    df = df.fillna('Bilinmiyor')\n",
        "\n",
        "    dokumanlar = []\n",
        "\n",
        "    # TÃ¼m veriyi alÄ±yoruz\n",
        "    print(f\"Toplam {len(df)} adet kayÄ±t iÅŸleniyor...\")\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # FormatÄ± sadeleÅŸtirdik. BaÅŸlÄ±k en Ã¼stte.\n",
        "        metin = (\n",
        "            f\"BaÅŸlÄ±k: {row['title']}\\n\"\n",
        "            f\"YÃ¶netmen: {row['director']}\\n\"\n",
        "            f\"YÄ±l: {row['release_year']}\\n\"\n",
        "            f\"TÃ¼r: {row['listed_in']}\\n\"\n",
        "            f\"Ã–zet: {row['description']}\\n\"\n",
        "            f\"Detay: Bu film {row['release_year']} yÄ±lÄ±nda yayÄ±nlanmÄ±ÅŸtÄ±r. {row['type']} kategorisindedir.\"\n",
        "        )\n",
        "        dokumanlar.append(metin)\n",
        "\n",
        "    print(f\"âœ… {len(dokumanlar)} adet iÃ§erik baÅŸarÄ±yla hazÄ±rlandÄ±.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ HATA: Dosya yok.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2KbD2AVjeQEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "print(\"VektÃ¶r veritabanÄ± (Ã‡ok Dilli) oluÅŸturuluyor...\")\n",
        "\n",
        "# DEÄÄ°ÅÄ°KLÄ°K BURADA:\n",
        "# ArtÄ±k TÃ¼rkÃ§e-Ä°ngilizce eÅŸleÅŸtirmesi yapabilen 'multilingual' modeli kullanÄ±yoruz.\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "# ChromaDB veritabanÄ±nÄ± kur\n",
        "# EÄŸer hata alÄ±rsan Ã¶nceki veritabanÄ±nÄ± temizlemek gerekebilir ama genellikle Ã¼zerine yazar.\n",
        "vektor_veritabani = Chroma.from_texts(dokumanlar, embedding=embedding_model)\n",
        "\n",
        "print(\"âœ… Ã‡ok dilli veritabanÄ± hazÄ±r! ArtÄ±k TÃ¼rkÃ§e sorgularÄ± Ä°ngilizce verilerle eÅŸleÅŸtirebilirim.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7LWL2D6zezqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "import re\n",
        "import random\n",
        "\n",
        "def rag_yanit(soru, top_k=3):\n",
        "    # 1. ADIM: Soruda YIL geÃ§iyor mu? (Regex ile 4 haneli sayÄ± kontrolÃ¼)\n",
        "    yil_tespiti = re.search(r'(\\d{4})', soru)\n",
        "\n",
        "    baglam = \"\"\n",
        "    kaynak_yontem = \"\"\n",
        "\n",
        "    # --- SENARYO A: YIL VARSA (Pandas Filtresi) ---\n",
        "    if yil_tespiti:\n",
        "        aranan_yil = int(yil_tespiti.group(1))\n",
        "        kaynak_yontem = \"DOÄRUDAN VERÄ° FÄ°LTRESÄ° (PANDAS)\"\n",
        "\n",
        "        # DataFrame Ã¼zerinden filtrele\n",
        "        uygun_filmler = df[df['release_year'] == aranan_yil]\n",
        "\n",
        "        if not uygun_filmler.empty:\n",
        "            secilenler = uygun_filmler.sample(n=min(2, len(uygun_filmler)))\n",
        "            context_list = []\n",
        "\n",
        "            print(f\"\\n[SÄ°STEM: {aranan_yil} yÄ±lÄ± iÃ§in {len(uygun_filmler)} film bulundu. Listeleniyor...]\")\n",
        "\n",
        "            for index, row in secilenler.iterrows():\n",
        "                metin = (\n",
        "                    f\"BaÅŸlÄ±k: {row['title']}\\n\"\n",
        "                    f\"YÃ¶netmen: {row['director']}\\n\"\n",
        "                    f\"YÄ±l: {row['release_year']}\\n\"\n",
        "                    f\"TÃ¼r: {row['listed_in']}\\n\"\n",
        "                    f\"Ã–zet: {row['description']}\"\n",
        "                )\n",
        "                print(f\"âœ… {row['title']} ({row['listed_in']})\")\n",
        "                context_list.append(metin)\n",
        "\n",
        "            baglam = \"\\n###\\n\".join(context_list)\n",
        "        else:\n",
        "            return f\"VeritabanÄ±mÄ±zda {aranan_yil} yapÄ±mÄ± film bulunamadÄ±.\"\n",
        "\n",
        "    # --- SENARYO B: YIL YOKSA (Yapay Zeka AramasÄ±) ---\n",
        "    else:\n",
        "        kaynak_yontem = \"VEKTÃ–R ARAMASI (AI)\"\n",
        "        aranan_dokumanlar = vektor_veritabani.similarity_search(soru, k=top_k)\n",
        "\n",
        "        print(f\"\\n[SÄ°STEM: Konuya gÃ¶re AI aramasÄ± yapÄ±lÄ±yor...]\")\n",
        "        context_list = []\n",
        "        for doc in aranan_dokumanlar:\n",
        "            # BaÅŸlÄ±ÄŸÄ± satÄ±r satÄ±r arayÄ±p bulalÄ±m (Hata riskini sÄ±fÄ±rlar)\n",
        "            lines = doc.page_content.split('\\n')\n",
        "            baslik = \"Bilinmiyor\"\n",
        "            for satir in lines:\n",
        "                if \"BaÅŸlÄ±k:\" in satir:\n",
        "                    baslik = satir.replace(\"BaÅŸlÄ±k: \", \"\").strip()\n",
        "\n",
        "            print(f\"ğŸ” Bulunan: {baslik}\")\n",
        "            context_list.append(doc.page_content)\n",
        "\n",
        "        baglam = \"\\n###\\n\".join(context_list)\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # 2. ADIM: Prompt\n",
        "    prompt = f\"\"\"Sen TÃ¼rkÃ§e konuÅŸan bir film uzmanÄ±sÄ±n.\n",
        "AÅŸaÄŸÄ±daki FÄ°LM BÄ°LGÄ°LERÄ°'ni kullanarak soruyu yanÄ±tla.\n",
        "\n",
        "FÄ°LM BÄ°LGÄ°LERÄ°:\n",
        "{baglam}\n",
        "\n",
        "SORU: {soru}\n",
        "\n",
        "KURALLAR:\n",
        "1. Sadece listedeki filmleri kullan.\n",
        "2. CevabÄ± uzatma, kÄ±sa ve net ol.\n",
        "3. CevabÄ± ÅŸu formatta ver: \"Ã–nerim: [Film AdÄ±]. Konusu: [Ã–zet]\"\n",
        "\n",
        "CEVAP:\"\"\"\n",
        "\n",
        "    # 3. ADIM: Ãœretim\n",
        "    # return_full_text=False parametresi prompt'un tekrar yazÄ±lmasÄ±nÄ± engeller\n",
        "    sonuc = llm_pipeline(prompt, return_full_text=False)[0][\"generated_text\"]\n",
        "\n",
        "    # Temizlik (Tekrarlayan cevaplarÄ± silmek iÃ§in)\n",
        "    cevap = sonuc.strip()\n",
        "    if \"Ã–nerim:\" in cevap:\n",
        "        # Bazen model cevabÄ± iki kere yazar, ilkini alalÄ±m.\n",
        "        cevap = \"Ã–nerim:\" + cevap.split(\"Ã–nerim:\")[1]\n",
        "        # EÄŸer arkasÄ±ndan tekrar \"Ã–nerim:\" geliyorsa keselim\n",
        "        if \"Ã–nerim:\" in cevap[1:]:\n",
        "             cevap = cevap.split(\"Ã–nerim:\")[0]\n",
        "\n",
        "    return cevap"
      ],
      "metadata": {
        "id": "2WeDNuAGe3Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================================================\")\n",
        "print(\"ğŸ¬ NETFLIX GURUSU (Ã‡Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yazÄ±n)\")\n",
        "print(\"================================================\\n\")\n",
        "\n",
        "while True:\n",
        "    soru = input(\"Soru sor: \")\n",
        "    if soru.lower() in ['Ã§Ä±kÄ±ÅŸ', 'exit', 'quit']:\n",
        "        print(\"Ä°yi seyirler ğŸ‘‹\")\n",
        "        break\n",
        "\n",
        "    print(\"ğŸ” AraÅŸtÄ±rÄ±yorum...\")\n",
        "    cevap = rag_yanit(soru)\n",
        "    print(f\"\\nğŸ¤– AI: {cevap}\\n\")\n",
        "    print(\"-\" * 40)\n",
        ""
      ],
      "metadata": {
        "id": "2Xk8gvNbfExJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yv3Wy90ug1MI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}